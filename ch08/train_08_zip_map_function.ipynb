{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬함수 > zip(), map() 함수 공부하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c')]\n"
     ]
    }
   ],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = ['a', 'b', 'c']\n",
    "\n",
    "zipped = zip(list1, list2) # zip(iterable 객체) : 짝을 지어 tuple 형태로 반환함\n",
    "result = list(zipped)\n",
    "\n",
    "print(result)  # [(1, 'a'), (2, 'b'), (3, 'c')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*zipped\t리스트 내부 요소들을 하나씩 풀어서 전달\n",
    "\n",
    "zip(*zipped)\t튜플 요소별로 다시 묶기 (역변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "unzipped = zip(*zipped) # 변수 unzipped는 iterator 객체 -> 2개의 iterable tuple로 구성됨\n",
    "# *zipped는 unpack하는 것으로 1,2,3/'a','b','c'으로 나눈다\n",
    "# (1,'a')을 unpack하면 1, 'a'로 나눈다\n",
    "# zip(*zipped)는 (1,2,3), ('a','b','c') 형태로 모은다 \n",
    "list1, list2 = map(list, unzipped) # map() : 리스트함수를 unzipped에 적용\n",
    "print(list1)  # [1, 2, 3]\n",
    "print(list2)  # ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num=1, name= a\n",
      "num=2, name= b\n",
      "num=3, name= c\n"
     ]
    }
   ],
   "source": [
    "zipped = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "numbers, names = zip(*zipped)\n",
    "\n",
    "for num, name in zip(numbers, names): #zip() 은 튜플형태로 만듬\n",
    "    print(f\"num={num}, name= {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "numbers = [1, 2, 3, 4]\n",
    "squared = map(square, numbers) # map () : square함수를 numbers에 적용\n",
    "# 리스트 numbers의 각 요소에 대해 square 함수를 적용한 결과를 하나씩 생성하는 반복 가능한 객체(iterator)를 만든다\n",
    "\n",
    "print(list(squared))  # [1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kiwi', 'apple', 'grape', 'banana']\n"
     ]
    }
   ],
   "source": [
    "data = ['apple', 'banana', 'kiwi', 'grape']\n",
    "\n",
    "# 문자열 길이순 정렬\n",
    "data.sort(key=lambda x: len(x)) # sort(key=정렬기준) 함수 # 여기서는 정렬 기준이 람다식임\n",
    "# lambda x의 x는 data 리스트의 각 요소(멤버)**를 의미\n",
    "print(data)  # ['kiwi', 'apple', 'grape', 'banana']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4]\n",
    "squared = map(lambda x: x ** 2, numbers)\n",
    "# x는 언제나 \"어떤 컬렉션의 한 원소\"를 의미\n",
    "#  lambda 함수는 리스트 등의 컬렉션을 순회할 때, 하나씩 꺼낸 요소가 x이다 \n",
    "\n",
    "print(list(squared))  # [1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = [4, 5, 6]\n",
    "\n",
    "result = map(lambda x, y: x + y, list1, list2)\n",
    "print(list(result))  # [5, 7, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter(function, iterable)\n",
    "\n",
    "- iterable의 요소들을 하나씩 function에 넣어\n",
    "- function(x)가 True인 요소만 남겨서 새로운 이터레이터로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 3, 4, 5, 6]\n",
    "evens = list(filter(lambda x: x % 2 == 0, nums))\n",
    "# filter() 함수는 if 문처럼 조건을 만족하는 요소만 걸러내는 기능\n",
    "print(evens)  # [2, 4, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "#reduce 함수 : \"누적(cumulative)\" 또는 \"축소(reduce)\" 연산을 수행하는 함수\n",
    "\n",
    "nums = [1, 2, 3, 4]\n",
    "product = reduce(lambda x, y: x * y, nums) # reduce()는 리스트 전체를 하나의 값으로 누적(accumulate)\n",
    "# (((1 * 2) * 3) * 4) = 24\n",
    "print(product)  # 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "람다식의 특징\n",
    "\n",
    "- 간결성> 작은 함수를 한 줄로 표현 가능\n",
    "- 익명성> 함수 이름 없이 사용 가능\n",
    "- 일회성 사용> 다른 함수(map, filter 등)의 인자로 자주 사용\n",
    "- 단점> 복잡한 로직에는 부적합 (가독성 떨어짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고차 함수(high-order function) 또는 콜백(callback) 개념\n",
    "\n",
    "- 함수를 다른 함수의 인수(argument) 전달\n",
    "- 함수를 변수에 저장\n",
    "- 함수를 인자로 전달\n",
    "- 함수의 반환값으로 또 다른 함수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "def ten_times(func):\n",
    "    for i in range(5):\n",
    "        func()\n",
    "        \n",
    "def print_hello():\n",
    "    print(\"hello\")\n",
    "    \n",
    "ten_times(print_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=7\n"
     ]
    }
   ],
   "source": [
    "def add(x,y):\n",
    "    return x+y\n",
    "\n",
    "def apply_operation(operation, x, y):\n",
    "    return operation(x,y)\n",
    "\n",
    "result = apply_operation(add,3,4)\n",
    "print(f\"result={result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "def power(item):\n",
    "    return item**2\n",
    "\n",
    "def under_three(item):\n",
    "    return item <3\n",
    "\n",
    "lst=[1,2,3,4,5]\n",
    "map_list = map(power, lst)\n",
    "print(list(map_list))\n",
    "\n",
    "filter_list = filter(under_three, lst)\n",
    "print(list(filter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "#def power(item):\n",
    "#    return item**\n",
    "# -> 람다식으로 변환\n",
    "power = lambda x: x*x\n",
    "\n",
    "#def under_three(item):\n",
    "#    return item <3\n",
    "# -> 람다식으로 변환\n",
    "under_three = lambda x: x<3\n",
    "\n",
    "lst=[1,2,3,4,5]\n",
    "map_list = map(power, lst)\n",
    "print(list(map_list))\n",
    "\n",
    "filter_list = filter(under_three, lst)\n",
    "print(list(filter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (2.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 사용:  False\n",
      "현재 사용 device cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda 사용: \u001b[39m\u001b[38;5;124m'\u001b[39m, USE_CUDA)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m현재 사용 device\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA Index: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA device:\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m USE_CUDA \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo GPU available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU 개수:\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:1026\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1026\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:363\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('cuda 사용: ', USE_CUDA)\n",
    "print('현재 사용 device', device)\n",
    "print('CUDA Index: ', torch.cuda.current_device())\n",
    "print('CUDA device:', torch.cuda.get_device_name(0) if USE_CUDA else 'No GPU available')\n",
    "print('GPU 개수:', torch.cuda.device_count())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
